{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8kYB0KoMTpLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part1"
      ],
      "metadata": {
        "id": "glyepA-WV09f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "YYSL1uKdTrPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_cpu.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "void matrixMultiplyCPU(float *A, float *B, float *C, int N) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            float sum = 0.0f;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                sum += A[i * N + k] * B[k * N + j];\n",
        "            }\n",
        "            C[i * N + j] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 1024;\n",
        "    size_t size = N * N * sizeof(float);\n",
        "\n",
        "    float *A = (float *)malloc(size);\n",
        "    float *B = (float *)malloc(size);\n",
        "    float *C = (float *)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        A[i] = rand() % 100 / 100.0f;\n",
        "        B[i] = rand() % 100 / 100.0f;\n",
        "    }\n",
        "\n",
        "    clock_t start = clock();\n",
        "    matrixMultiplyCPU(A, B, C, N);\n",
        "    clock_t end = clock();\n",
        "\n",
        "    double elapsed = (double)(end - start) / CLOCKS_PER_SEC;\n",
        "    printf(\"CPU execution time (N=%d): %f seconds\\n\", N, elapsed);\n",
        "\n",
        "    free(A); free(B); free(C);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiyHAhFJTsGS",
        "outputId": "b088adb8-d33a-4e34-bbc5-68a384f06eb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_cpu.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc matrix_cpu.c -o matrix_cpu -O2"
      ],
      "metadata": {
        "id": "RiSFNkw2UAW9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== CPU Matrix Multiplication Tests ===\\n\")\n",
        "!./matrix_cpu 256\n",
        "!./matrix_cpu 512\n",
        "!./matrix_cpu 768\n",
        "!./matrix_cpu 1024\n",
        "!./matrix_cpu 1536\n",
        "!./matrix_cpu 2048"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aszsLXqbUEF1",
        "outputId": "f68f583b-e018-4faf-d2be-366ab8d01ba8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CPU Matrix Multiplication Tests ===\n",
            "\n",
            "CPU execution time (N=256): 0.020597 seconds\n",
            "CPU execution time (N=512): 0.201802 seconds\n",
            "CPU execution time (N=768): 0.681257 seconds\n",
            "CPU execution time (N=1024): 3.224413 seconds\n",
            "CPU execution time (N=1536): 17.811165 seconds\n",
            "CPU execution time (N=2048): 83.500410 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2"
      ],
      "metadata": {
        "id": "3dXc1cYDWb09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_gpu.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void matrixMultiplyGPU(float *A, float *B, float *C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        float sum = 0.0f;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            sum += A[row * N + k] * B[k * N + col];\n",
        "        }\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 1024;\n",
        "    size_t size = N * N * sizeof(float);\n",
        "\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = rand() % 100 / 100.0f;\n",
        "        h_B[i] = rand() % 100 / 100.0f;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    dim3 dimBlock(16, 16);\n",
        "    dim3 dimGrid((N + 15) / 16, (N + 15) / 16);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixMultiplyGPU<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Naive GPU time (N=%d): %.3f ms (%.3f sec)\\n\", N, milliseconds, milliseconds/1000.0);\n",
        "\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwganLbOUFtu",
        "outputId": "e1c6bb19-29b3-4640-e644-433ae8839173"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_gpu.cu -o matrix_gpu"
      ],
      "metadata": {
        "id": "Uw6Gqm1tU0OK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3"
      ],
      "metadata": {
        "id": "rj8bmepYWl1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Naive GPU Matrix Multiplication Tests ===\\n\")\n",
        "!./matrix_gpu 256\n",
        "!./matrix_gpu 512\n",
        "!./matrix_gpu 768\n",
        "!./matrix_gpu 1024\n",
        "!./matrix_gpu 1536\n",
        "!./matrix_gpu 2048\n",
        "!./matrix_gpu 4096"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHR9zqizU1xy",
        "outputId": "609e2fcf-8c2f-4c15-aeff-03a7c7c147ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Naive GPU Matrix Multiplication Tests ===\n",
            "\n",
            "Naive GPU time (N=256): 9.144 ms (0.009 sec)\n",
            "Naive GPU time (N=512): 7.388 ms (0.007 sec)\n",
            "Naive GPU time (N=768): 12.828 ms (0.013 sec)\n",
            "Naive GPU time (N=1024): 11.195 ms (0.011 sec)\n",
            "Naive GPU time (N=1536): 11.692 ms (0.012 sec)\n",
            "Naive GPU time (N=2048): 11.023 ms (0.011 sec)\n",
            "Naive GPU time (N=4096): 7.387 ms (0.007 sec)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4"
      ],
      "metadata": {
        "id": "Vf8eey29XDDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_tiled.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "\n",
        "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
        "    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int Row = by * TILE_WIDTH + ty;\n",
        "    int Col = bx * TILE_WIDTH + tx;\n",
        "\n",
        "    float Pvalue = 0.0;\n",
        "\n",
        "    for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n",
        "        if (Row < N && (m*TILE_WIDTH+tx) < N)\n",
        "            ds_A[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];\n",
        "        else\n",
        "            ds_A[ty][tx] = 0.0f;\n",
        "\n",
        "        if (Col < N && (m*TILE_WIDTH+ty) < N)\n",
        "            ds_B[ty][tx] = B[(m*TILE_WIDTH + ty) * N + Col];\n",
        "        else\n",
        "            ds_B[ty][tx] = 0.0f;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_WIDTH; ++k)\n",
        "            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (Row < N && Col < N)\n",
        "        C[Row * N + Col] = Pvalue;\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 1024;\n",
        "    size_t size = N * N * sizeof(float);\n",
        "\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = rand() % 100 / 100.0f;\n",
        "        h_B[i] = rand() % 100 / 100.0f;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "    dim3 dimGrid((N + TILE_WIDTH - 1) / TILE_WIDTH, (N + TILE_WIDTH - 1) / TILE_WIDTH);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixMultiplyTiled<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Optimized GPU time (N=%d): %.3f ms (%.3f sec)\\n\", N, milliseconds, milliseconds/1000.0);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHPhCphJU4Rp",
        "outputId": "0dc501c0-fbf4-4652-9271-77844568c391"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_tiled.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_tiled.cu -o matrix_tiled"
      ],
      "metadata": {
        "id": "iF_3GSWiVMxD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Optimized GPU (Tiled) Matrix Multiplication Tests ===\\n\")\n",
        "!./matrix_tiled 256\n",
        "!./matrix_tiled 512\n",
        "!./matrix_tiled 768\n",
        "!./matrix_tiled 1024\n",
        "!./matrix_tiled 1536\n",
        "!./matrix_tiled 2048\n",
        "!./matrix_tiled 4096"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exdZSx55VcdX",
        "outputId": "8cd1343d-430c-41df-9a1f-ec3528425642"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Optimized GPU (Tiled) Matrix Multiplication Tests ===\n",
            "\n",
            "Optimized GPU time (N=256): 7.480 ms (0.007 sec)\n",
            "Optimized GPU time (N=512): 7.296 ms (0.007 sec)\n",
            "Optimized GPU time (N=768): 7.423 ms (0.007 sec)\n",
            "Optimized GPU time (N=1024): 7.482 ms (0.007 sec)\n",
            "Optimized GPU time (N=1536): 7.229 ms (0.007 sec)\n",
            "Optimized GPU time (N=2048): 7.320 ms (0.007 sec)\n",
            "Optimized GPU time (N=4096): 7.370 ms (0.007 sec)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 6"
      ],
      "metadata": {
        "id": "QpnAdPxWYs41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_cublas.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 1024;\n",
        "    size_t size = N * N * sizeof(float);\n",
        "\n",
        "    float *h_A = (float *)malloc(size);\n",
        "    float *h_B = (float *)malloc(size);\n",
        "    float *h_C = (float *)malloc(size);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = rand() % 100 / 100.0f;\n",
        "        h_B[i] = rand() % 100 / 100.0f;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "\n",
        "    float alpha = 1.0f;\n",
        "    float beta = 0.0f;\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "                N, N, N,\n",
        "                &alpha,\n",
        "                d_B, N,\n",
        "                d_A, N,\n",
        "                &beta,\n",
        "                d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"cuBLAS GPU time (N=%d): %.3f ms (%.3f sec)\\n\", N, milliseconds, milliseconds/1000.0);\n",
        "\n",
        "    cublasDestroy(handle);\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG1oVq78X58k",
        "outputId": "58b2ccb3-b802-47d1-f663-96ad689e3520"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_cublas.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_cublas.cu -o matrix_cublas -lcublas"
      ],
      "metadata": {
        "id": "9hWO_9h3X6tF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== cuBLAS Matrix Multiplication Tests ===\\n\")\n",
        "!./matrix_cublas 256\n",
        "!./matrix_cublas 512\n",
        "!./matrix_cublas 768\n",
        "!./matrix_cublas 1024\n",
        "!./matrix_cublas 1536\n",
        "!./matrix_cublas 2048\n",
        "!./matrix_cublas 4096"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrGhllRuX8hT",
        "outputId": "2a747450-4575-49fb-fa06-ae3088d6ee63"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== cuBLAS Matrix Multiplication Tests ===\n",
            "\n",
            "cuBLAS GPU time (N=256): 80.034 ms (0.080 sec)\n",
            "cuBLAS GPU time (N=512): 5.376 ms (0.005 sec)\n",
            "cuBLAS GPU time (N=768): 5.620 ms (0.006 sec)\n",
            "cuBLAS GPU time (N=1024): 6.163 ms (0.006 sec)\n",
            "cuBLAS GPU time (N=1536): 7.875 ms (0.008 sec)\n",
            "cuBLAS GPU time (N=2048): 11.310 ms (0.011 sec)\n",
            "cuBLAS GPU time (N=4096): 53.277 ms (0.053 sec)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 7"
      ],
      "metadata": {
        "id": "gkmZlA0oZvoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_lib.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "\n",
        "__global__ void matrixMultiplyTiled(float *A, float *B, float *C, int N) {\n",
        "    __shared__ float ds_A[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float ds_B[TILE_WIDTH][TILE_WIDTH];\n",
        "\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int Row = by * TILE_WIDTH + ty;\n",
        "    int Col = bx * TILE_WIDTH + tx;\n",
        "\n",
        "    float Pvalue = 0.0;\n",
        "\n",
        "    for (int m = 0; m < (N + TILE_WIDTH - 1) / TILE_WIDTH; ++m) {\n",
        "        if (Row < N && (m*TILE_WIDTH+tx) < N)\n",
        "            ds_A[ty][tx] = A[Row * N + m * TILE_WIDTH + tx];\n",
        "        else\n",
        "            ds_A[ty][tx] = 0.0f;\n",
        "\n",
        "        if (Col < N && (m*TILE_WIDTH+ty) < N)\n",
        "            ds_B[ty][tx] = B[(m*TILE_WIDTH + ty) * N + Col];\n",
        "        else\n",
        "            ds_B[ty][tx] = 0.0f;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int k = 0; k < TILE_WIDTH; ++k)\n",
        "            Pvalue += ds_A[ty][k] * ds_B[k][tx];\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (Row < N && Col < N)\n",
        "        C[Row * N + Col] = Pvalue;\n",
        "}\n",
        "\n",
        "// Exposed C function for Python\n",
        "extern \"C\" void gpu_matrix_multiply(float *h_A, float *h_B, float *h_C, int N) {\n",
        "    size_t size = N * N * sizeof(float);\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimBlock(TILE_WIDTH, TILE_WIDTH);\n",
        "    dim3 dimGrid((N + TILE_WIDTH - 1) / TILE_WIDTH, (N + TILE_WIDTH - 1) / TILE_WIDTH);\n",
        "\n",
        "    matrixMultiplyTiled<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBm3lCsyX-iu",
        "outputId": "bc2e1acf-7a20-4372-de7a-367cd761b830"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_lib.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Xcompiler -fPIC -shared matrix_lib.cu -o libmatrix.so"
      ],
      "metadata": {
        "id": "8z9O4WJaZcfv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_cuda_lib.py\n",
        "import ctypes\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load shared library\n",
        "lib = ctypes.cdll.LoadLibrary(\"./libmatrix.so\")\n",
        "\n",
        "# Define argument types\n",
        "lib.gpu_matrix_multiply.argtypes = [\n",
        "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        "    ctypes.c_int\n",
        "]\n",
        "\n",
        "# Test with different sizes\n",
        "sizes = [256, 512, 1024, 2048]\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Python calling CUDA library - Performance Test\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for N in sizes:\n",
        "    A = np.random.rand(N, N).astype(np.float32)\n",
        "    B = np.random.rand(N, N).astype(np.float32)\n",
        "    C = np.zeros((N, N), dtype=np.float32)\n",
        "\n",
        "    start = time.time()\n",
        "    lib.gpu_matrix_multiply(A.ravel(), B.ravel(), C.ravel(), N)\n",
        "    end = time.time()\n",
        "\n",
        "    print(f\"N={N}: {(end - start)*1000:.3f} ms ({end - start:.4f} sec)\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1UfC7zNZe-y",
        "outputId": "0396c9c9-bcc6-4ece-fb4a-7c94d219cfb4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_cuda_lib.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_cuda_lib.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPJSZELlZiXI",
        "outputId": "58643038-003f-4a76-cb17-0967376ed06e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Python calling CUDA library - Performance Test\n",
            "============================================================\n",
            "N=256: 210.550 ms (0.2105 sec)\n",
            "N=512: 1.522 ms (0.0015 sec)\n",
            "N=1024: 3.601 ms (0.0036 sec)\n",
            "N=2048: 20.458 ms (0.0205 sec)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile convolution_lib.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "// 2D Convolution kernel\n",
        "__global__ void convolveGPU(float *image, float *filter, float *output,\n",
        "                            int imageWidth, int imageHeight,\n",
        "                            int filterSize) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (row < imageHeight && col < imageWidth) {\n",
        "        float sum = 0.0f;\n",
        "        int halfFilter = filterSize / 2;\n",
        "\n",
        "        for (int fRow = 0; fRow < filterSize; fRow++) {\n",
        "            for (int fCol = 0; fCol < filterSize; fCol++) {\n",
        "                int imageRow = row - halfFilter + fRow;\n",
        "                int imageCol = col - halfFilter + fCol;\n",
        "\n",
        "                // Handle boundaries (zero padding)\n",
        "                if (imageRow >= 0 && imageRow < imageHeight &&\n",
        "                    imageCol >= 0 && imageCol < imageWidth) {\n",
        "                    sum += image[imageRow * imageWidth + imageCol] *\n",
        "                           filter[fRow * filterSize + fCol];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        output[row * imageWidth + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Exposed C function for Python\n",
        "extern \"C\" void gpu_convolve(float *h_image, float *h_filter, float *h_output,\n",
        "                             int imageWidth, int imageHeight, int filterSize) {\n",
        "    size_t imageSize = imageWidth * imageHeight * sizeof(float);\n",
        "    size_t filterSize_bytes = filterSize * filterSize * sizeof(float);\n",
        "\n",
        "    float *d_image, *d_filter, *d_output;\n",
        "    cudaMalloc((void**)&d_image, imageSize);\n",
        "    cudaMalloc((void**)&d_filter, filterSize_bytes);\n",
        "    cudaMalloc((void**)&d_output, imageSize);\n",
        "\n",
        "    cudaMemcpy(d_image, h_image, imageSize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_filter, h_filter, filterSize_bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimBlock(16, 16);\n",
        "    dim3 dimGrid((imageWidth + 15) / 16, (imageHeight + 15) / 16);\n",
        "\n",
        "    convolveGPU<<<dimGrid, dimBlock>>>(d_image, d_filter, d_output,\n",
        "                                       imageWidth, imageHeight, filterSize);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(h_output, d_output, imageSize, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(d_image);\n",
        "    cudaFree(d_filter);\n",
        "    cudaFree(d_output);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2a2iVqPZkGh",
        "outputId": "9ed6bb4d-07e8-4637-cede-560a9d717cb1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing convolution_lib.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Xcompiler -fPIC -shared convolution_lib.cu -o libconvolution.so"
      ],
      "metadata": {
        "id": "asZ3IT3cedKQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_convolution.py\n",
        "import ctypes\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load library\n",
        "lib = ctypes.cdll.LoadLibrary(\"./libconvolution.so\")\n",
        "\n",
        "lib.gpu_convolve.argtypes = [\n",
        "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        "    np.ctypeslib.ndpointer(dtype=np.float32, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
        "    ctypes.c_int, ctypes.c_int, ctypes.c_int\n",
        "]\n",
        "\n",
        "# Edge detection filters\n",
        "sobel_x = np.array([[-1, 0, 1],\n",
        "                    [-2, 0, 2],\n",
        "                    [-1, 0, 1]], dtype=np.float32)\n",
        "\n",
        "sobel_y = np.array([[-1, -2, -1],\n",
        "                    [ 0,  0,  0],\n",
        "                    [ 1,  2,  1]], dtype=np.float32)\n",
        "\n",
        "blur = np.array([[1, 1, 1],\n",
        "                 [1, 1, 1],\n",
        "                 [1, 1, 1]], dtype=np.float32) / 9.0\n",
        "\n",
        "# Create test image (circle)\n",
        "size = 512\n",
        "image = np.zeros((size, size), dtype=np.float32)\n",
        "center = size // 2\n",
        "radius = size // 4\n",
        "for i in range(size):\n",
        "    for j in range(size):\n",
        "        if (i - center)**2 + (j - center)**2 < radius**2:\n",
        "            image[i, j] = 1.0\n",
        "\n",
        "# Apply filters\n",
        "output_x = np.zeros_like(image)\n",
        "output_y = np.zeros_like(image)\n",
        "output_blur = np.zeros_like(image)\n",
        "\n",
        "print(\"Applying edge detection filters...\")\n",
        "\n",
        "start = time.time()\n",
        "lib.gpu_convolve(image.ravel(), sobel_x.ravel(), output_x.ravel(), size, size, 3)\n",
        "time_x = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "lib.gpu_convolve(image.ravel(), sobel_y.ravel(), output_y.ravel(), size, size, 3)\n",
        "time_y = time.time() - start\n",
        "\n",
        "start = time.time()\n",
        "lib.gpu_convolve(image.ravel(), blur.ravel(), output_blur.ravel(), size, size, 3)\n",
        "time_blur = time.time() - start\n",
        "\n",
        "# Combine edge detection\n",
        "edges = np.sqrt(output_x**2 + output_y**2)\n",
        "\n",
        "print(f\"\\nPerformance (512x512 image):\")\n",
        "print(f\"Sobel X: {time_x*1000:.3f} ms\")\n",
        "print(f\"Sobel Y: {time_y*1000:.3f} ms\")\n",
        "print(f\"Blur: {time_blur*1000:.3f} ms\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "axes[0, 0].imshow(image, cmap='gray')\n",
        "axes[0, 0].set_title('Original Image')\n",
        "axes[0, 1].imshow(output_x, cmap='gray')\n",
        "axes[0, 1].set_title('Sobel X (Vertical Edges)')\n",
        "axes[0, 2].imshow(output_y, cmap='gray')\n",
        "axes[0, 2].set_title('Sobel Y (Horizontal Edges)')\n",
        "axes[1, 0].imshow(edges, cmap='gray')\n",
        "axes[1, 0].set_title('Combined Edge Detection')\n",
        "axes[1, 1].imshow(output_blur, cmap='gray')\n",
        "axes[1, 1].set_title('Blur Filter')\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "for ax in axes.flat:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('convolution_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDone\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn6YXFy4efED",
        "outputId": "ecb21200-c700-4d7f-ae3c-56629876483a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_convolution.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_convolution.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rggF3a1WehDV",
        "outputId": "c0c320ea-164d-4660-fe29-ec872fbb33d9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying edge detection filters...\n",
            "\n",
            "Performance (512x512 image):\n",
            "Sobel X: 201.844 ms\n",
            "Sobel Y: 1.183 ms\n",
            "Blur: 1.002 ms\n",
            "Figure(1200x800)\n",
            "\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 8"
      ],
      "metadata": {
        "id": "OozjEJ4chZvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile convolution_cpu.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "// CPU convolution\n",
        "void convolveCPU(float *image, float *filter, float *output,\n",
        "                 int imageWidth, int imageHeight, int filterSize) {\n",
        "\n",
        "    int half = filterSize / 2;\n",
        "\n",
        "    for (int row = 0; row < imageHeight; row++) {\n",
        "        for (int col = 0; col < imageWidth; col++) {\n",
        "            float sum = 0.0f;\n",
        "\n",
        "            for (int fr = 0; fr < filterSize; fr++) {\n",
        "                for (int fc = 0; fc < filterSize; fc++) {\n",
        "                    int r = row - half + fr;\n",
        "                    int c = col - half + fc;\n",
        "\n",
        "                    if (r >= 0 && r < imageHeight &&\n",
        "                        c >= 0 && c < imageWidth) {\n",
        "                        sum += image[r * imageWidth + c] *\n",
        "                               filter[fr * filterSize + fc];\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            output[row * imageWidth + col] = sum;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 512;\n",
        "    int filterSize = (argc > 2) ? atoi(argv[2]) : 3;\n",
        "\n",
        "    size_t imageBytes = N * N * sizeof(float);\n",
        "    size_t filterBytes = filterSize * filterSize * sizeof(float);\n",
        "\n",
        "    float *image = (float *)malloc(imageBytes);\n",
        "    float *output = (float *)malloc(imageBytes);\n",
        "    float *filter = (float *)malloc(filterBytes);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++)\n",
        "        image[i] = (i % 255) / 255.0f;\n",
        "\n",
        "    for (int i = 0; i < filterSize * filterSize; i++)\n",
        "        filter[i] = 1.0f / (filterSize * filterSize);\n",
        "\n",
        "    clock_t start = clock();\n",
        "    convolveCPU(image, filter, output, N, N, filterSize);\n",
        "    clock_t end = clock();\n",
        "\n",
        "    double timeSec = (double)(end - start) / CLOCKS_PER_SEC;\n",
        "    printf(\"CPU Convolution: Image=%dx%d Filter=%dx%d Time=%.4f sec\\n\",\n",
        "           N, N, filterSize, filterSize, timeSec);\n",
        "\n",
        "    free(image);\n",
        "    free(output);\n",
        "    free(filter);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb-qsWh-hZWM",
        "outputId": "008fb1e8-c13b-44cc-dfee-d132d3cc7afe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting convolution_cpu.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc convolution_cpu.c -O2 -o convolution_cpu\n"
      ],
      "metadata": {
        "id": "Pi8xwQAPh_KC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./convolution_cpu 256 3\n",
        "!./convolution_cpu 512 3\n",
        "!./convolution_cpu 1024 3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGmogcs0iFHZ",
        "outputId": "b711b5f4-4190-46a2-aba4-4d323e74278b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Convolution: Image=256x256 Filter=3x3 Time=0.0013 sec\n",
            "CPU Convolution: Image=512x512 Filter=3x3 Time=0.0041 sec\n",
            "CPU Convolution: Image=1024x1024 Filter=3x3 Time=0.0156 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile convolution_gpu.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void convolveGPU(float *img, float *fil, float *out,\n",
        "                            int W, int H, int F) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int half = F / 2;\n",
        "\n",
        "    if (x < W && y < H) {\n",
        "        float sum = 0.0f;\n",
        "        for (int fy = 0; fy < F; fy++)\n",
        "            for (int fx = 0; fx < F; fx++) {\n",
        "                int iy = y - half + fy;\n",
        "                int ix = x - half + fx;\n",
        "                if (iy >= 0 && iy < H && ix >= 0 && ix < W)\n",
        "                    sum += img[iy * W + ix] * fil[fy * F + fx];\n",
        "            }\n",
        "        out[y * W + x] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char **argv) {\n",
        "    int N = (argc > 1) ? atoi(argv[1]) : 512;\n",
        "    int F = (argc > 2) ? atoi(argv[2]) : 3;\n",
        "\n",
        "    size_t imgSize = N * N * sizeof(float);\n",
        "    size_t filSize = F * F * sizeof(float);\n",
        "\n",
        "    float *h_img = (float*)malloc(imgSize);\n",
        "    float *h_fil = (float*)malloc(filSize);\n",
        "    float *h_out = (float*)malloc(imgSize);\n",
        "\n",
        "    for (int i = 0; i < N * N; i++) h_img[i] = (i % 255) / 255.0f;\n",
        "    for (int i = 0; i < F * F; i++) h_fil[i] = 1.0f / (F * F);\n",
        "\n",
        "    float *d_img, *d_fil, *d_out;\n",
        "    cudaMalloc(&d_img, imgSize);\n",
        "    cudaMalloc(&d_fil, filSize);\n",
        "    cudaMalloc(&d_out, imgSize);\n",
        "\n",
        "    cudaMemcpy(d_img, h_img, imgSize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_fil, h_fil, filSize, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 block(16,16);\n",
        "    dim3 grid((N+15)/16, (N+15)/16);\n",
        "\n",
        "    cudaEvent_t s,e;\n",
        "    cudaEventCreate(&s); cudaEventCreate(&e);\n",
        "    cudaEventRecord(s);\n",
        "\n",
        "    convolveGPU<<<grid,block>>>(d_img,d_fil,d_out,N,N,F);\n",
        "    cudaEventRecord(e);\n",
        "    cudaEventSynchronize(e);\n",
        "\n",
        "    float ms;\n",
        "    cudaEventElapsedTime(&ms,s,e);\n",
        "\n",
        "    printf(\"CUDA Convolution N=%d F=%d Time=%.3f ms\\n\", N, F, ms);\n",
        "\n",
        "    cudaFree(d_img); cudaFree(d_fil); cudaFree(d_out);\n",
        "    free(h_img); free(h_fil); free(h_out);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlPLZp85iHYm",
        "outputId": "d7107ff0-f05a-4cd5-e2b1-6f829963bc41"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting convolution_gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc convolution_gpu.cu -o convolution_gpu\n"
      ],
      "metadata": {
        "id": "KbKCpSjBi6Z5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./convolution_gpu 256 3\n",
        "!./convolution_gpu 512 3\n",
        "!./convolution_gpu 1024 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As1FpmUQi_AI",
        "outputId": "81f65cd8-f6aa-4e50-ab5e-5f20b209e851"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Convolution N=256 F=3 Time=8.970 ms\n",
            "CUDA Convolution N=512 F=3 Time=7.639 ms\n",
            "CUDA Convolution N=1024 F=3 Time=7.303 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Image Size | CPU Time (ms) | CUDA Time (ms) |\n",
        "| ---------- | ------------- | -------------- |\n",
        "| 256×256    | 1.4           | 76.5           |\n",
        "| 512×512    | 4.3           | 11.1           |\n",
        "| 1024×1024  | 28.6          | 10.9           |\n"
      ],
      "metadata": {
        "id": "VDjhUNbbjlwV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1E8TsfSjmUr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}